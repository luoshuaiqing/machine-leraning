{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import cifar10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I loaded the data from cifar10, which is the same as what we downloaded so does not matter\n",
    "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "          'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "target_label = 2\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = cifar10.load_data()\n",
    "\n",
    "t_target = t_train==target_label\n",
    "t_target = t_target.reshape(t_target.size)\n",
    "training_set = x_train[t_target]\n",
    "\n",
    "t_target_2 = t_test==target_label\n",
    "t_target_2 = t_target_2.reshape(t_target_2.size)\n",
    "test_set = x_test[t_target_2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(training_set[21][0][0])\n",
    "print(training_set.shape)\n",
    "all_data = np.concatenate((training_set, test_set), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Those 6000 images have 6000 × 32 × 32 pixels. Choose at least 10% of the pixels randomly. It is strongly recommended that you choose a large number or all of the pixels. You will have between P = 614400 and P = 6144000 pixels. Each pixel is an RGB vector with three elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"I chose all the datapoints for question c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Run k-means clustering on the P vectors using k = 4. The centers of the clusters\n",
    "will be your main colors. Convert the colored images to k-color images by con-\n",
    "verting each pixel’s value to the closest main color in terms of Euclidean distance.\n",
    "These are the outputs of your network, whose each pixel falls in one of those k\n",
    "2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "pixels = []\n",
    "pixels = np.reshape(all_data, (6000 * 32 * 32, 3))\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(pixels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(kmeans.cluster_centers_,\"\\n=======================\")\n",
    "import math\n",
    "index = 0\n",
    "for pixel in pixels:\n",
    "    min_dist = 100000000\n",
    "    min_mean = kmeans.cluster_centers_[0]\n",
    "    for mean in kmeans.cluster_centers_:\n",
    "        dist = math.sqrt((pixel[0] - mean[0])**2 + (pixel[1] - mean[1])**2 + (pixel[2] - mean[2])**2)\n",
    "        min_mean = mean if dist < min_dist else min_mean\n",
    "        min_dist = dist if dist < min_dist else min_dist\n",
    "    \n",
    "    pixels[index] = min_mean\n",
    "    index += 1\n",
    "    \n",
    "# images = np.reshape(pixels, (6000, 32, 32, 3))\n",
    "# output_images = []\n",
    "# for image in images:\n",
    "#     img = Image.fromarray(image, 'RGB')\n",
    "#     output_images.append(img)\n",
    "\n",
    "# you can show any image by calling output_images[index].show()\n",
    "# e.g. output_images[0].show()\n",
    "\n",
    "_kmeans = kmeans.cluster_centers_.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training label and test label\n",
    "new_pixels = []\n",
    "for pixel in pixels:\n",
    "    new_pixel = [0, 0, 0, 0]\n",
    "    index_2 = 0\n",
    "    for kmean in _kmeans:\n",
    "        if np.array_equal(kmean, pixel):\n",
    "            new_pixel[index_2] = 1\n",
    "            new_pixels.append(new_pixel)\n",
    "        index_2 += 1\n",
    "\n",
    "print(new_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Use any tool (e.g., openCV or scikit-learn) to obtain grayscale 32 × 32 × 1 images from the original 32 × 32 × 3 images. The grayscale images are inputs of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import data\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "grayscale_images = []\n",
    "for original in all_data:\n",
    "    grayscale = rgb2gray(original)\n",
    "    grayscale_images.append(grayscale)\n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "#     ax = axes.ravel()\n",
    "\n",
    "#     ax[0].imshow(original)\n",
    "#     ax[0].set_title(\"Original\")\n",
    "#     ax[1].imshow(grayscale, cmap=plt.cm.gray)\n",
    "#     ax[1].set_title(\"Grayscale\")\n",
    "\n",
    "#     fig.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "print(np.asarray(grayscale_images).shape)\n",
    "\n",
    "training_data = np.asarray(grayscale_images[:5000])\n",
    "testing_data = np.asarray(grayscale_images[5000:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten , Dense, Activation,Dropout\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16,(5,5),activation='relu', \n",
    "                                 input_shape=(32,32,1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (5, 5), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "model.add(layers.Dense(32*32*4))\n",
    "model.add(layers.Dense(32*32*4))\n",
    "model.add(layers.Reshape((32, 32, 4)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_images = training_data.reshape((5000, 32, 32, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = testing_data.reshape((1000, 32, 32, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "new_pixels = np.reshape(new_pixels, (6000, 32, 32, 4))\n",
    "training_labels = new_pixels[:5000]\n",
    "testing_labels = new_pixels[5000:]\n",
    "\n",
    "from livelossplot import PlotLossesKeras\n",
    "# training the data and report the training error and validation error during each epoch\n",
    "history = model.fit(train_images, training_labels, epochs=5, validation_data=(test_images, testing_labels), callbacks=[PlotLossesKeras()])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the test loss and test accuracy\n",
    "test_loss, test_acc = model.evaluate(test_images, testing_labels)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test Error Rate:', 1 - test_acc)\n",
    "\n",
    "print(\"\\n\\n===================================================\\n\\n\")\n",
    "\n",
    "# get the training loss and training accuracy\n",
    "train_loss, train_acc = model.evaluate(train_images, training_labels)\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Train loss:', train_loss)\n",
    "print('Train Error Rate:', 1 - train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test_images[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visually compare the artificially colored versions of the first 10 images in the test set with the original images.\n",
    "predictions = model.predict_classes(test_images[:10])\n",
    "# print(kmeans.cluster_centers_)\n",
    "pixels = []\n",
    "for row in predictions:\n",
    "    for col in row:\n",
    "        for val in col:\n",
    "            RGB_val = kmeans.cluster_centers_[val]\n",
    "            pixels.append(RGB_val)        \n",
    "\n",
    "    \n",
    "pixels = np.reshape(pixels, (10, 32, 32, 3))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(10):    \n",
    "#     show test result\n",
    "    plt.imshow(pixels[i].astype(int))\n",
    "    plt.show()\n",
    "#     show original result\n",
    "    plt.imshow(test_set[i])\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extra credit for k = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import cifar10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I loaded the data from cifar10, which is the same as what we downloaded so does not matter\n",
    "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "          'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "target_label = 2\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = cifar10.load_data()\n",
    "\n",
    "t_target = t_train==target_label\n",
    "t_target = t_target.reshape(t_target.size)\n",
    "training_set = x_train[t_target]\n",
    "\n",
    "t_target_2 = t_test==target_label\n",
    "t_target_2 = t_target_2.reshape(t_target_2.size)\n",
    "test_set = x_test[t_target_2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(training_set[21][0][0])\n",
    "print(training_set.shape)\n",
    "all_data = np.concatenate((training_set, test_set), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Those 6000 images have 6000 × 32 × 32 pixels. Choose at least 10% of the pixels randomly. It is strongly recommended that you choose a large number or all of the pixels. You will have between P = 614400 and P = 6144000 pixels. Each pixel is an RGB vector with three elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"I chose all the datapoints for question c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Run k-means clustering on the P vectors using k = 4. The centers of the clusters\n",
    "will be your main colors. Convert the colored images to k-color images by con-\n",
    "verting each pixel’s value to the closest main color in terms of Euclidean distance.\n",
    "These are the outputs of your network, whose each pixel falls in one of those k\n",
    "2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "pixels = []\n",
    "pixels = np.reshape(all_data, (6000 * 32 * 32, 3))\n",
    "kmeans = KMeans(n_clusters=16, random_state=0).fit(pixels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(kmeans.cluster_centers_,\"\\n=======================\")\n",
    "import math\n",
    "index = 0\n",
    "for pixel in pixels:\n",
    "    min_dist = 100000000\n",
    "    min_mean = kmeans.cluster_centers_[0]\n",
    "    for mean in kmeans.cluster_centers_:\n",
    "        dist = math.sqrt((pixel[0] - mean[0])**2 + (pixel[1] - mean[1])**2 + (pixel[2] - mean[2])**2)\n",
    "        min_mean = mean if dist < min_dist else min_mean\n",
    "        min_dist = dist if dist < min_dist else min_dist\n",
    "    \n",
    "    pixels[index] = min_mean\n",
    "    index += 1\n",
    "    \n",
    "# images = np.reshape(pixels, (6000, 32, 32, 3))\n",
    "# output_images = []\n",
    "# for image in images:\n",
    "#     img = Image.fromarray(image, 'RGB')\n",
    "#     output_images.append(img)\n",
    "\n",
    "# you can show any image by calling output_images[index].show()\n",
    "# e.g. output_images[0].show()\n",
    "\n",
    "_kmeans = kmeans.cluster_centers_.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training label and test label\n",
    "new_pixels = []\n",
    "for pixel in pixels:\n",
    "    new_pixel = [0] * 16\n",
    "    index_2 = 0\n",
    "    for kmean in _kmeans:\n",
    "        if np.array_equal(kmean, pixel):\n",
    "            new_pixel[index_2] = 1\n",
    "            new_pixels.append(new_pixel)\n",
    "        index_2 += 1\n",
    "\n",
    "print(new_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Use any tool (e.g., openCV or scikit-learn) to obtain grayscale 32 × 32 × 1 images from the original 32 × 32 × 3 images. The grayscale images are inputs of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import data\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "grayscale_images = []\n",
    "for original in all_data:\n",
    "    grayscale = rgb2gray(original)\n",
    "    grayscale_images.append(grayscale)\n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "#     ax = axes.ravel()\n",
    "\n",
    "#     ax[0].imshow(original)\n",
    "#     ax[0].set_title(\"Original\")\n",
    "#     ax[1].imshow(grayscale, cmap=plt.cm.gray)\n",
    "#     ax[1].set_title(\"Grayscale\")\n",
    "\n",
    "#     fig.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "print(np.asarray(grayscale_images).shape)\n",
    "\n",
    "training_data = np.asarray(grayscale_images[:5000])\n",
    "testing_data = np.asarray(grayscale_images[5000:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten , Dense, Activation,Dropout\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16,(5,5),activation='relu', \n",
    "                                 input_shape=(32,32,1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (5, 5), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "model.add(layers.Dense(32*32*16))\n",
    "model.add(layers.Dense(32*32*16))\n",
    "model.add(layers.Reshape((32, 32, 16)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_images = training_data.reshape((5000, 32, 32, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = testing_data.reshape((1000, 32, 32, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "new_pixels = np.reshape(new_pixels, (6000, 32, 32, 16))\n",
    "training_labels = new_pixels[:5000]\n",
    "testing_labels = new_pixels[5000:]\n",
    "\n",
    "from livelossplot import PlotLossesKeras\n",
    "# training the data and report the training error and validation error during each epoch\n",
    "history = model.fit(train_images, training_labels, epochs=5, validation_data=(test_images, testing_labels), callbacks=[PlotLossesKeras()])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the test loss and test accuracy\n",
    "test_loss, test_acc = model.evaluate(test_images, testing_labels)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test Error Rate:', 1 - test_acc)\n",
    "\n",
    "print(\"\\n\\n===================================================\\n\\n\")\n",
    "\n",
    "# get the training loss and training accuracy\n",
    "train_loss, train_acc = model.evaluate(train_images, training_labels)\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Train loss:', train_loss)\n",
    "print('Train Error Rate:', 1 - train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visually compare the artificially colored versions of the first 10 images in the test set with the original images.\n",
    "predictions = model.predict_classes(test_images[:10])\n",
    "# print(kmeans.cluster_centers_)\n",
    "pixels = []\n",
    "for row in predictions:\n",
    "    for col in row:\n",
    "        for val in col:\n",
    "            RGB_val = kmeans.cluster_centers_[val]\n",
    "            pixels.append(RGB_val)        \n",
    "\n",
    "    \n",
    "pixels = np.reshape(pixels, (10, 32, 32, 3))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(10):    \n",
    "#     show test result\n",
    "    plt.imshow(pixels[i].astype(int))\n",
    "    plt.show()\n",
    "#     show original result\n",
    "    plt.imshow(test_set[i])\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra credit for k = 24\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import cifar10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I loaded the data from cifar10, which is the same as what we downloaded so does not matter\n",
    "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "          'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "target_label = 2\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = cifar10.load_data()\n",
    "\n",
    "t_target = t_train==target_label\n",
    "t_target = t_target.reshape(t_target.size)\n",
    "training_set = x_train[t_target]\n",
    "\n",
    "t_target_2 = t_test==target_label\n",
    "t_target_2 = t_target_2.reshape(t_target_2.size)\n",
    "test_set = x_test[t_target_2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(training_set[21][0][0])\n",
    "print(training_set.shape)\n",
    "all_data = np.concatenate((training_set, test_set), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Those 6000 images have 6000 × 32 × 32 pixels. Choose at least 10% of the pixels randomly. It is strongly recommended that you choose a large number or all of the pixels. You will have between P = 614400 and P = 6144000 pixels. Each pixel is an RGB vector with three elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"I chose all the datapoints for question c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Run k-means clustering on the P vectors using k = 4. The centers of the clusters\n",
    "will be your main colors. Convert the colored images to k-color images by con-\n",
    "verting each pixel’s value to the closest main color in terms of Euclidean distance.\n",
    "These are the outputs of your network, whose each pixel falls in one of those k\n",
    "2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "pixels = []\n",
    "pixels = np.reshape(all_data, (6000 * 32 * 32, 3))\n",
    "kmeans = KMeans(n_clusters=24, random_state=0).fit(pixels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(kmeans.cluster_centers_,\"\\n=======================\")\n",
    "import math\n",
    "index = 0\n",
    "for pixel in pixels:\n",
    "    min_dist = 100000000\n",
    "    min_mean = kmeans.cluster_centers_[0]\n",
    "    for mean in kmeans.cluster_centers_:\n",
    "        dist = math.sqrt((pixel[0] - mean[0])**2 + (pixel[1] - mean[1])**2 + (pixel[2] - mean[2])**2)\n",
    "        min_mean = mean if dist < min_dist else min_mean\n",
    "        min_dist = dist if dist < min_dist else min_dist\n",
    "    \n",
    "    pixels[index] = min_mean\n",
    "    index += 1\n",
    "    \n",
    "# images = np.reshape(pixels, (6000, 32, 32, 3))\n",
    "# output_images = []\n",
    "# for image in images:\n",
    "#     img = Image.fromarray(image, 'RGB')\n",
    "#     output_images.append(img)\n",
    "\n",
    "# you can show any image by calling output_images[index].show()\n",
    "# e.g. output_images[0].show()\n",
    "\n",
    "_kmeans = kmeans.cluster_centers_.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training label and test label\n",
    "new_pixels = []\n",
    "for pixel in pixels:\n",
    "    new_pixel = [0] * 24\n",
    "    index_2 = 0\n",
    "    for kmean in _kmeans:\n",
    "        if np.array_equal(kmean, pixel):\n",
    "            new_pixel[index_2] = 1\n",
    "            new_pixels.append(new_pixel)\n",
    "        index_2 += 1\n",
    "\n",
    "print(new_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Use any tool (e.g., openCV or scikit-learn) to obtain grayscale 32 × 32 × 1 images from the original 32 × 32 × 3 images. The grayscale images are inputs of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import data\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "grayscale_images = []\n",
    "for original in all_data:\n",
    "    grayscale = rgb2gray(original)\n",
    "    grayscale_images.append(grayscale)\n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "#     ax = axes.ravel()\n",
    "\n",
    "#     ax[0].imshow(original)\n",
    "#     ax[0].set_title(\"Original\")\n",
    "#     ax[1].imshow(grayscale, cmap=plt.cm.gray)\n",
    "#     ax[1].set_title(\"Grayscale\")\n",
    "\n",
    "#     fig.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "print(np.asarray(grayscale_images).shape)\n",
    "\n",
    "training_data = np.asarray(grayscale_images[:5000])\n",
    "testing_data = np.asarray(grayscale_images[5000:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten , Dense, Activation,Dropout\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16,(5,5),activation='relu', \n",
    "                                 input_shape=(32,32,1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (5, 5), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "model.add(layers.Dense(32*32*24))\n",
    "model.add(layers.Dense(32*32*24))\n",
    "model.add(layers.Reshape((32, 32, 24)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_images = training_data.reshape((5000, 32, 32, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = testing_data.reshape((1000, 32, 32, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "new_pixels = np.reshape(new_pixels, (6000, 32, 32, 24))\n",
    "training_labels = new_pixels[:5000]\n",
    "testing_labels = new_pixels[5000:]\n",
    "\n",
    "from livelossplot import PlotLossesKeras\n",
    "# training the data and report the training error and validation error during each epoch\n",
    "history = model.fit(train_images, training_labels, epochs=5, validation_data=(test_images, testing_labels), callbacks=[PlotLossesKeras()])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the test loss and test accuracy\n",
    "test_loss, test_acc = model.evaluate(test_images, testing_labels)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test Error Rate:', 1 - test_acc)\n",
    "\n",
    "print(\"\\n\\n===================================================\\n\\n\")\n",
    "\n",
    "# get the training loss and training accuracy\n",
    "train_loss, train_acc = model.evaluate(train_images, training_labels)\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Train loss:', train_loss)\n",
    "print('Train Error Rate:', 1 - train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visually compare the artificially colored versions of the first 10 images in the test set with the original images.\n",
    "predictions = model.predict_classes(test_images[:10])\n",
    "# print(kmeans.cluster_centers_)\n",
    "pixels = []\n",
    "for row in predictions:\n",
    "    for col in row:\n",
    "        for val in col:\n",
    "            RGB_val = kmeans.cluster_centers_[val]\n",
    "            pixels.append(RGB_val)        \n",
    "\n",
    "    \n",
    "pixels = np.reshape(pixels, (10, 32, 32, 3))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(10):    \n",
    "#     show test result\n",
    "    plt.imshow(pixels[i].astype(int))\n",
    "    plt.show()\n",
    "#     show original result\n",
    "    plt.imshow(test_set[i])\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra credit for k = 32\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import cifar10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I loaded the data from cifar10, which is the same as what we downloaded so does not matter\n",
    "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "          'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "target_label = 2\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = cifar10.load_data()\n",
    "\n",
    "t_target = t_train==target_label\n",
    "t_target = t_target.reshape(t_target.size)\n",
    "training_set = x_train[t_target]\n",
    "\n",
    "t_target_2 = t_test==target_label\n",
    "t_target_2 = t_target_2.reshape(t_target_2.size)\n",
    "test_set = x_test[t_target_2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(training_set[21][0][0])\n",
    "print(training_set.shape)\n",
    "all_data = np.concatenate((training_set, test_set), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Those 6000 images have 6000 × 32 × 32 pixels. Choose at least 10% of the pixels randomly. It is strongly recommended that you choose a large number or all of the pixels. You will have between P = 614400 and P = 6144000 pixels. Each pixel is an RGB vector with three elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"I chose all the datapoints for question c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Run k-means clustering on the P vectors using k = 4. The centers of the clusters\n",
    "will be your main colors. Convert the colored images to k-color images by con-\n",
    "verting each pixel’s value to the closest main color in terms of Euclidean distance.\n",
    "These are the outputs of your network, whose each pixel falls in one of those k\n",
    "2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "pixels = []\n",
    "pixels = np.reshape(all_data, (6000 * 32 * 32, 3))\n",
    "kmeans = KMeans(n_clusters=32, random_state=0).fit(pixels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(kmeans.cluster_centers_,\"\\n=======================\")\n",
    "import math\n",
    "index = 0\n",
    "for pixel in pixels:\n",
    "    min_dist = 100000000\n",
    "    min_mean = kmeans.cluster_centers_[0]\n",
    "    for mean in kmeans.cluster_centers_:\n",
    "        dist = math.sqrt((pixel[0] - mean[0])**2 + (pixel[1] - mean[1])**2 + (pixel[2] - mean[2])**2)\n",
    "        min_mean = mean if dist < min_dist else min_mean\n",
    "        min_dist = dist if dist < min_dist else min_dist\n",
    "    \n",
    "    pixels[index] = min_mean\n",
    "    index += 1\n",
    "    \n",
    "# images = np.reshape(pixels, (6000, 32, 32, 3))\n",
    "# output_images = []\n",
    "# for image in images:\n",
    "#     img = Image.fromarray(image, 'RGB')\n",
    "#     output_images.append(img)\n",
    "\n",
    "# you can show any image by calling output_images[index].show()\n",
    "# e.g. output_images[0].show()\n",
    "\n",
    "_kmeans = kmeans.cluster_centers_.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training label and test label\n",
    "new_pixels = []\n",
    "for pixel in pixels:\n",
    "    new_pixel = [0] * 32\n",
    "    index_2 = 0\n",
    "    for kmean in _kmeans:\n",
    "        if np.array_equal(kmean, pixel):\n",
    "            new_pixel[index_2] = 1\n",
    "            new_pixels.append(new_pixel)\n",
    "        index_2 += 1\n",
    "\n",
    "print(new_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Use any tool (e.g., openCV or scikit-learn) to obtain grayscale 32 × 32 × 1 images from the original 32 × 32 × 3 images. The grayscale images are inputs of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import data\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "grayscale_images = []\n",
    "for original in all_data:\n",
    "    grayscale = rgb2gray(original)\n",
    "    grayscale_images.append(grayscale)\n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "#     ax = axes.ravel()\n",
    "\n",
    "#     ax[0].imshow(original)\n",
    "#     ax[0].set_title(\"Original\")\n",
    "#     ax[1].imshow(grayscale, cmap=plt.cm.gray)\n",
    "#     ax[1].set_title(\"Grayscale\")\n",
    "\n",
    "#     fig.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "print(np.asarray(grayscale_images).shape)\n",
    "\n",
    "training_data = np.asarray(grayscale_images[:5000])\n",
    "testing_data = np.asarray(grayscale_images[5000:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten , Dense, Activation,Dropout\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16,(5,5),activation='relu', \n",
    "                                 input_shape=(32,32,1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (5, 5), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "model.add(layers.Dense(32*32*32))\n",
    "model.add(layers.Dense(32*32*32))\n",
    "model.add(layers.Reshape((32, 32, 32)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_images = training_data.reshape((5000, 32, 32, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = testing_data.reshape((1000, 32, 32, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "new_pixels = np.reshape(new_pixels, (6000, 32, 32, 32))\n",
    "training_labels = new_pixels[:5000]\n",
    "testing_labels = new_pixels[5000:]\n",
    "\n",
    "from livelossplot import PlotLossesKeras\n",
    "# training the data and report the training error and validation error during each epoch\n",
    "history = model.fit(train_images, training_labels, epochs=5, validation_data=(test_images, testing_labels), callbacks=[PlotLossesKeras()])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the test loss and test accuracy\n",
    "test_loss, test_acc = model.evaluate(test_images, testing_labels)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test Error Rate:', 1 - test_acc)\n",
    "\n",
    "print(\"\\n\\n===================================================\\n\\n\")\n",
    "\n",
    "# get the training loss and training accuracy\n",
    "train_loss, train_acc = model.evaluate(train_images, training_labels)\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Train loss:', train_loss)\n",
    "print('Train Error Rate:', 1 - train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visually compare the artificially colored versions of the first 10 images in the test set with the original images.\n",
    "predictions = model.predict_classes(test_images[:10])\n",
    "# print(kmeans.cluster_centers_)\n",
    "pixels = []\n",
    "for row in predictions:\n",
    "    for col in row:\n",
    "        for val in col:\n",
    "            RGB_val = kmeans.cluster_centers_[val]\n",
    "            pixels.append(RGB_val)        \n",
    "\n",
    "    \n",
    "pixels = np.reshape(pixels, (10, 32, 32, 3))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(10):    \n",
    "#     show test result\n",
    "    plt.imshow(pixels[i].astype(int))\n",
    "    plt.show()\n",
    "#     show original result\n",
    "    plt.imshow(test_set[i])\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
